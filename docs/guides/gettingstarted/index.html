<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Getting Started · Apify SDK</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="&lt;p&gt;Without the right tools, crawling and scraping the web can be a difficult thing. At the very least, you need an HTTP client to make the necessary requests, but that only gets you raw HTML and sometimes not even that. Then you have to read this HTML and extract the data you&#x27;re interested in. Once extracted, it must be stored in a machine readable format and easily accessible for further processing, because it is the processed data that hold value.&lt;/p&gt;
"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Getting Started · Apify SDK"/><meta property="og:type" content="website"/><meta property="og:url" content="https://sdk.apify.com/index.html"/><meta property="og:description" content="&lt;p&gt;Without the right tools, crawling and scraping the web can be a difficult thing. At the very least, you need an HTTP client to make the necessary requests, but that only gets you raw HTML and sometimes not even that. Then you have to read this HTML and extract the data you&#x27;re interested in. Once extracted, it must be stored in a machine readable format and easily accessible for further processing, because it is the processed data that hold value.&lt;/p&gt;
"/><meta property="og:image" content="https://sdk.apify.com/img/apify_logo.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://sdk.apify.com/img/apify_logo.png"/><link rel="shortcut icon" href="/img/favicon.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/monokai-sublime.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><link rel="stylesheet" href="/css/prism.css"/><link rel="stylesheet" href="/css/main.css"/></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/apify_logo.svg" alt="Apify SDK"/><h2 class="headerTitleWithLogo">Apify SDK</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li><li class="siteNavGroupActive"><a href="/docs/guides/motivation" target="_self">Guide</a></li><li class=""><a href="/docs/examples/basiccrawler" target="_self">Examples</a></li><li class="siteNavGroupActive"><a href="/docs/api/apify" target="_self">Reference</a></li><li class=""><a href="https://github.com/apifytech/apify-js" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><i></i></div><h2><i>›</i><span>Guide</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Guide</h3><ul><li class="navListItem"><a class="navItem" href="/docs/guides/motivation">Motivation</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/docs/guides/gettingstarted">Getting Started</a></li><li class="navListItem"><a class="navItem" href="/docs/guides/gettingstartedquick">Getting Started Quick</a></li><li class="navListItem"><a class="navItem" href="/docs/guides/whatisanactor">What is an Actor</a></li><li class="navListItem"><a class="navItem" href="/docs/guides/environmentvariables">Environment Variables</a></li><li class="navListItem"><a class="navItem" href="/docs/guides/datastorage">Data Storage</a></li><li class="navListItem"><a class="navItem" href="/docs/guides/puppeteerliveview">Puppeteer Live View</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Reference</h3><ul><li class="navListItem"><a class="navItem" href="/docs/api/apify">Apify</a></li><li class="navListItem"><a class="navItem" href="/docs/api/autoscaledpool">AutoscaledPool</a></li><li class="navListItem"><a class="navItem" href="/docs/api/basiccrawler">BasicCrawler</a></li><li class="navListItem"><a class="navItem" href="/docs/api/cheeriocrawler">CheerioCrawler</a></li><li class="navListItem"><a class="navItem" href="/docs/api/dataset">Dataset</a></li><li class="navListItem"><a class="navItem" href="/docs/api/keyvaluestore">KeyValueStore</a></li><li class="navListItem"><a class="navItem" href="/docs/api/pseudourl">PseudoUrl</a></li><li class="navListItem"><a class="navItem" href="/docs/api/puppeteercrawler">PuppeteerCrawler</a></li><li class="navListItem"><a class="navItem" href="/docs/api/puppeteerpool">PuppeteerPool</a></li><li class="navListItem"><a class="navItem" href="/docs/api/request">Request</a></li><li class="navListItem"><a class="navItem" href="/docs/api/requestlist">RequestList</a></li><li class="navListItem"><a class="navItem" href="/docs/api/requestqueue">RequestQueue</a></li><li class="navListItem"><a class="navItem" href="/docs/api/utils">utils</a></li><li class="navListItem"><a class="navItem" href="/docs/api/puppeteer">utils.puppeteer</a></li><li class="navListItem"><a class="navItem" href="/docs/api/social">utils.social</a></li></ul></div></div></section></div><script>
            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              const headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                if (event.target.tagName === 'A') {
                  document.body.classList.remove('tocActive');
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle">Getting Started</h1></header><article><div><span><p>Without the right tools, crawling and scraping the web can be a difficult thing. At the very least, you need an HTTP client to make the necessary requests, but that only gets you raw HTML and sometimes not even that. Then you have to read this HTML and extract the data you're interested in. Once extracted, it must be stored in a machine readable format and easily accessible for further processing, because it is the processed data that hold value.</p>
<p>Apify SDK covers the process end-to-end. From crawling the web for links and scraping the raw data to storing it in various machine readable formats, ready for processing. With this guide in hand, you should have your own data extraction solutions up and running in a few hours.</p>
<h2><a class="anchor" aria-hidden="true" id="intro"></a><a href="#intro" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Intro</h2>
<p>The goal of this getting started guide is to provide a step-by-step introduction to all the features of the Apify SDK. It will walk you through creating the simplest of crawlers that only print text to console, all the way up to complex systems that crawl pages, interact with them as if a real user were sitting in front of a real browser and output structured data.</p>
<p>Since Apify SDK is usable both locally on any computer and on the
<a href="https://my.apify.com" target="_blank">Apify Platform</a>,
you will be able to use the source code in both environments interchangeably. Nevertheless, some initial setup is still required, so choose your preferred starting environment and let's get into it.</p>
<h2><a class="anchor" aria-hidden="true" id="setting-up-locally"></a><a href="#setting-up-locally" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setting up locally</h2>
<p>To run Apify SDK on your own computer, you need to meet the following pre-requisites first:</p>
<ol>
<li>Have Node.js version 8.14 or higher installed.
<ul>
<li>Visit <a href="https://nodejs.org/en/download/" target="_blank">Node.js website</a> to download or use <a href="https://github.com/creationix/nvm" target="_blank">nvm</a></li>
</ul></li>
<li>Have NPM installed.
<ul>
<li>NPM comes bundled with Node.js so you should already have it. If not, reinstall Node.js.</li>
</ul></li>
</ol>
<p>If you're not certain, confirm the pre-requisites by running:</p>
<pre><code class="hljs css language-bash">node -v
</code></pre>
<pre><code class="hljs css language-bash"><span class="token function">npm</span> -v
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="adding-apify-sdk-to-an-existing-project"></a><a href="#adding-apify-sdk-to-an-existing-project" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Adding Apify SDK to an existing project</h3>
<p>Apify SDK can be added as a dependency into any Node.js project, so if you already have a project that you'd like to add web crawling, scraping and automation capabilities to, just run the following command in the project's folder and you're good to go.</p>
<pre><code class="hljs css language-bash"><span class="token function">npm</span> <span class="token function">install</span> apify
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="creating-a-new-project"></a><a href="#creating-a-new-project" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Creating a new project</h3>
<p>The fastest and best way to create new projects with the Apify SDK is to use our own
<a href="https://www.npmjs.com/package/apify-cli" target="_blank">Apify CLI</a>.
This command line tool allows you to create, run and manage Apify projects with ease, including their deployment to the <a href="https://my.apify.com" target="_blank">Apify Platform</a> if you wish to run them in the cloud after developing them locally.</p>
<p>Let's install the Apify CLI with the following command:</p>
<pre><code class="hljs css language-bash"><span class="token function">npm</span> <span class="token function">install</span> -g apify-cli
</code></pre>
<p>Once the installation finishes, all you need to do to set up an Apify SDK project is to run:</p>
<pre><code class="hljs css language-bash">apify create my-new-project
</code></pre>
<p>A prompt will be shown, asking to choose a template. Disregard the different options for now and choose the template labeled <code>Hello world</code>. The command will now create a new directory in your current working directory, called <code>my-new-project</code>, create a <code>package.json</code> in this folder and install all the necessary dependencies. It will also add example source code that you can immediately run.</p>
<p>Let's try that!</p>
<pre><code class="hljs css language-bash"><span class="token function">cd</span> my-new-project
</code></pre>
<pre><code class="hljs css language-bash">apify run
</code></pre>
<p>You should start seeing log messages in the terminal as the system boots up and after a second, a Chromium browser window should pop up. In the window, you'll see quickly changing pages and back in the terminal, you should see the titles (contents of the &lt;title&gt; HTML tags) of the pages printed.</p>
<p>You can always terminate the crawl with a keypress in the terminal:</p>
<pre><code class="hljs css language-bash">CTRL+C
</code></pre>
<p>Did you see all that? If you did, congratulations! You're ready to go!</p>
<h2><a class="anchor" aria-hidden="true" id="setting-up-on-the-apify-platform"></a><a href="#setting-up-on-the-apify-platform" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setting up on the Apify Platform</h2>
<p>Maybe you don't have Node.js installed and don't want the hassle. Or you can't install anything on your computer because you're using a company provided one. Or perhaps you'd just prefer to start working in the cloud right away. Well, no worries, we've got you covered.</p>
<p>The <a href="https://my.apify.com" target="_blank">Apify Platform</a> is the foundational product of <a href="https://www.apify.com" target="_blank">Apify</a>. It's a serverless cloud computing platform, specifically designed for any web automation jobs, that may include crawling and scraping, but really works amazing for any batch jobs and long running tasks.</p>
<p>It comes with a free account, so let's go to our
<a href="https://my.apify.com/sign-up" target="_blank">sign-up page</a>
and create one, if you haven't already. Don't forget to verify your email. Without it, you won't be able to run any projects.</p>
<p>Once you're in, you might by prompted by our in-app help to walk through a step-by-step guide into some of our new features. Feel free to finish that, if you'd like, but once you're done, click on the <strong>Actors</strong> tab in the left menu. You might be tempted to go directly to Crawlers, because what the heck are <strong>Actors</strong>, right? Bear with me, <strong>Actors</strong> are the tool that you really want! To read more about them, see: <a href="./whatisanactor">What is an Actor</a>.</p>
<h3><a class="anchor" aria-hidden="true" id="creating-a-new-project-1"></a><a href="#creating-a-new-project-1" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Creating a new project</h3>
<p>In the page that shows after clicking on Actors in the left menu, choose <strong>Create new</strong>. Give it a name in the form that opens, let's say, <code>my-new-actor</code>. Disregard all the available options for now and save your changes.</p>
<p>Now click on the <strong>Sources</strong> tab at the top. Disregard the version and environment variables inputs for now and proceed directly to <strong>Source code</strong>. This is where you develop the actor, if you choose not to do it locally. Just press <strong>Run</strong> below the <strong>Source code</strong> panel. It will automatically build and run the example source code. You should start seeing log messages that represent the build and after the build is complete, log messages of the running actor. Feel free to check out the other <strong>Run</strong> tabs, such as <strong>Info</strong>, where you can find useful information about the run, or <strong>Key-value-store</strong>, where the actor's <strong>INPUT</strong> and <strong>OUTPUT</strong> are stored.</p>
<p>Good job. You're now ready to run your own source code on the Apify Platform. For more information visit the
<a href="https://www.apify.com/docs/actor" target="_blank">Actor documentation page</a>,
where you'll find everything about the platform's various options.</p>
<h2><a class="anchor" aria-hidden="true" id="first-crawler"></a><a href="#first-crawler" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>First crawler</h2>
<p>Whether you've chosen to develop locally or in the cloud, it's time to start writing some actual source code. But before we do, let me just briefly introduce all the Apify SDK classes necessary to make it happen.</p>
<h3><a class="anchor" aria-hidden="true" id="the-general-idea"></a><a href="#the-general-idea" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The general idea</h3>
<p>There are 3 crawler classes available for use in the Apify SDK. <a href="../api/basiccrawler"><code>BasicCrawler</code></a>, <a href="../api/cheeriocrawler"><code>CheerioCrawler</code></a> and <a href="../api/puppeteercrawler"><code>PuppeteerCrawler</code></a>. We'll talk about their differences later. Now, let's talk about what they have in common.</p>
<p>All the crawlers' general idea is to go to a web page, open it, do some stuff there, save some results and continue to the next page, until it's done its job. So each time the crawler needs to find answers to two questions: <strong>Where should I go?</strong> and <strong>What should I do there?</strong>. Answering those two questions is the only setup mandatory to run the crawlers.</p>
<h3><a class="anchor" aria-hidden="true" id="the-where-request-requestlist-and-requestqueue"></a><a href="#the-where-request-requestlist-and-requestqueue" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Where - <code>Request</code>, <code>RequestList</code> and <code>RequestQueue</code></h3>
<p>All crawlers use instances of the <a href="../api/request"><code>Request</code></a> class to determine where they need to go. Each request may hold a lot of information, but at the very least, it must hold a URL - a web page to open. But having only one URL would not make sense for crawling. We need to either have a pre-existing list of our own URLs that we wish to visit, perhaps a thousand, or a million, or we need to build this list dynamically as we crawl, adding more and more URLs to the list as we progress.</p>
<p>A representation of the pre-existing list is an instance of the <a href="../api/requestlist"><code>RequestList</code></a> class. It is a static, immutable list of URLs and other metadata (see the <a href="../api/request"><code>Request</code></a> object) that the crawler will visit, one by one, retrying whenever an error occurs, until there are no more <code>Requests</code> to process.</p>
<p><a href="../api/requestqueue"><code>RequestQueue</code></a> on the other hand, represents a dynamic queue of <code>Requests</code>. One that can be updated at runtime by adding more pages - <code>Requests</code> to process. This allows the crawler to open one page, extract interesting URLs, such as links to other pages on the same domain, add them to the queue (called <em>enqueuing</em>) and repeat this process to build a queue of tens of thousands or more URLs while knowing only a single one at the beginning.</p>
<p><code>RequestList</code> and <code>RequestQueue</code> are essential for the crawler's operation. There is no other way to supply <code>Requests</code> = &quot;pages to crawl&quot; to the crawlers. At least one of them always needs to be provided while setting up. You can also use both at the same time, if you wish.</p>
<h3><a class="anchor" aria-hidden="true" id="the-what-handlepagefunction"></a><a href="#the-what-handlepagefunction" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The What - <code>handlePageFunction</code></h3>
<p>The <code>handlePageFunction</code> is the brain of the crawler. It tells it what to do at each and every page it visits. Generally it handles extraction of data from the page, processing the data, saving it, calling APIs, doing calculations and whatever else you need it to do, really.</p>
<p>The <code>handlePageFunction</code> is provided by you, the user, and invoked automatically by the crawler for each <code>Request</code> from either the <code>RequestList</code> or <code>RequestQueue</code>. It always receives a single argument and that is a plain <code>Object</code>. Its properties change depending on the used crawler class, but it always includes at least the <code>request</code> property, which represents the currently crawled <code>Request</code> instance (i.e. the URL the crawler is visiting and related metadata) and the <code>autoscaledPool</code> property, which is an instance of the <a href="../api/autoscaledpool"><code>AutoscaledPool</code></a> class and we'll talk about it in detail later.</p>
<pre><code class="hljs css language-js"><span class="token comment">// The object received as a single argument by the handlePageFunction</span>
<span class="token punctuation">{</span>
    request<span class="token punctuation">:</span> Request<span class="token punctuation">,</span>
    autoscaledPool<span class="token punctuation">:</span> AutoscaledPool
<span class="token punctuation">}</span>
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="putting-it-all-together"></a><a href="#putting-it-all-together" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Putting it all together</h3>
<p>Enough theory! Let's put some of those hard learned facts into practice. We learned above that we need <code>Requests</code> and a <code>handlePageFunction</code> to setup a crawler. We will also use the <a href="../api/apify#module_Apify.main"><code>Apify.main()</code></a> function. It's not mandatory, but it makes our life easier. We'll learn about it in detail later on.</p>
<p>Let's start super easy. Visit one page, get its title and close. First of all we need to require Apify, to make all of its features available to us:</p>
<pre><code class="hljs css language-js"><span class="token keyword">const</span> Apify <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'apify'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Easy right? It doesn't get much more difficult, trust me. For the purposes of this tutorial, we'll be scraping our own webpage <a href="https://www.apify.com" target="_blank">https://www.apify.com</a>. Now, to get there, we need a <code>Request</code> with the page's URL in one of our sources, <code>RequestList</code> or <code>RequestQueue</code>. Let's go with <code>RequestQueue</code> for now.</p>
<pre><code class="hljs css language-js"><span class="token keyword">const</span> Apify <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'apify'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// This is how you use the Apify.main() function.</span>
Apify<span class="token punctuation">.</span><span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">async</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">{</span>
    <span class="token comment">// First we create the request queue instance.</span>
    <span class="token keyword">const</span> requestQueue <span class="token operator">=</span> <span class="token keyword">await</span> Apify<span class="token punctuation">.</span><span class="token function">openRequestQueue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// And then we add a request to it.</span>
    <span class="token keyword">await</span> requestQueue<span class="token punctuation">.</span><span class="token function">addRequest</span><span class="token punctuation">(</span><span class="token punctuation">{</span> url<span class="token punctuation">:</span> <span class="token string">'https://www.apify.com'</span> <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<blockquote>
<p>If you're not familiar with the <code>async</code> and <code>await</code> keywords used in the example, trust that it is a native syntax in modern JavaScript and you can <a href="https://nikgrozev.com/2017/10/01/async-await/">learn more about it here</a>.</p>
</blockquote>
<p>The <a href="../api/requestqueue#RequestQueue+addRequest"><code>requestQueue.addRequest()</code></a> function automatically converts the plain object we passed to it to a <code>Request</code> instance, so now we have a <code>requestQueue</code> that holds one <code>request</code> which points to <code>https://www.apify.com</code>. Now we need the <code>handlePageFunction</code>.</p>
<pre><code class="hljs css language-js"><span class="token comment">// We'll define the function separately so it's more obvious.</span>
<span class="token keyword">const</span> handlePageFunction <span class="token operator">=</span> <span class="token keyword">async</span> <span class="token punctuation">(</span><span class="token punctuation">{</span> request<span class="token punctuation">,</span> $ <span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">{</span>
    <span class="token comment">// This should look familiar if you ever worked with jQuery.</span>
    <span class="token comment">// We're just getting the text content of the &lt;title> HTML element.</span>
    <span class="token keyword">const</span> title <span class="token operator">=</span> <span class="token function">$</span><span class="token punctuation">(</span><span class="token string">'title'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token template-string"><span class="token string">`The title of "</span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>request<span class="token punctuation">.</span>url<span class="token interpolation-punctuation punctuation">}</span></span><span class="token string">" is: </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>title<span class="token interpolation-punctuation punctuation">}</span></span><span class="token string">.`</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Wait, where did the <code>$</code> come from? Remember what we learned about the <code>handlePageFunction</code> earlier. It expects a plain <code>Object</code> as an argument that will always have a <code>request</code> property, but it will also have other properties, depending on the chosen crawler class. Well, <code>$</code> is a property provided by the <code>CheerioCrawler</code> class which we'll set up right now.</p>
<pre><code class="hljs css language-js"><span class="token keyword">const</span> Apify <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'apify'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

Apify<span class="token punctuation">.</span><span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">async</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">{</span>
    <span class="token keyword">const</span> requestQueue <span class="token operator">=</span> <span class="token keyword">await</span> Apify<span class="token punctuation">.</span><span class="token function">openRequestQueue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">await</span> requestQueue<span class="token punctuation">.</span><span class="token function">addRequest</span><span class="token punctuation">(</span><span class="token punctuation">{</span> url<span class="token punctuation">:</span> <span class="token string">'https://www.apify.com'</span> <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token keyword">const</span> handlePageFunction <span class="token operator">=</span> <span class="token keyword">async</span> <span class="token punctuation">(</span><span class="token punctuation">{</span> request<span class="token punctuation">,</span> $ <span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">{</span>
        <span class="token keyword">const</span> title <span class="token operator">=</span> <span class="token function">$</span><span class="token punctuation">(</span><span class="token string">'title'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
        console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token template-string"><span class="token string">`The title of "</span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>request<span class="token punctuation">.</span>url<span class="token interpolation-punctuation punctuation">}</span></span><span class="token string">" is: </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">${</span>title<span class="token interpolation-punctuation punctuation">}</span></span><span class="token string">.`</span></span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    
    <span class="token comment">// Set up the crawler, passing a single options object as an argument.</span>
    <span class="token keyword">const</span> crawler <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Apify<span class="token punctuation">.</span>CheerioCrawler</span><span class="token punctuation">(</span><span class="token punctuation">{</span>
        requestQueue<span class="token punctuation">,</span>
        handlePageFunction
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token keyword">await</span> crawler<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>And we're done! You just created your first crawler from scratch. It will download the HTML of <code>https://www.apify.com</code>, find the <code>&lt;title&gt;</code> element, get its text content and print it to console. Good job!</p>
<p>To run the code locally, copy and paste the code, if you haven't already typed it in yourself, to the <code>main.js</code> file in the <code>my-new-project</code> we created earlier and run <code>apify run</code> from that project's directory.</p>
<p>To run the code on Apify Platform, just replace the original example with your new code and hit Run.</p>
<p>Whichever environment you choose, you should see the message <code>The title of &quot;https://www.apify.com&quot; is: Web Scraping, Data Extraction and Automation - Apify.</code> printed to the screen. If you do, congratulations and let's move onto some bigger challenges! And if you feel like you don't really know what just happened there, no worries, it will all become clear when you learn more about the <code>CheerioCrawler</code>.</p>
<h2><a class="anchor" aria-hidden="true" id="cheeriocrawler-aka-jquery-crawler"></a><a href="#cheeriocrawler-aka-jquery-crawler" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>CheerioCrawler aka jQuery crawler</h2>
<p>This is the crawler that we used in our earlier example. Our simplest and also the fastest crawling solution. If you're familiar with <code>jQuery</code>, you'll understand <code>CheerioCrawler</code> in minutes. <a href="https://www.npmjs.com/package/cheerio" target="_blank">Cheerio</a> is essentially <code>jQuery</code> for Node.js. It offers the same API, including the familiar <code>$</code> object. You can use it, as you would <code>jQuery</code>, for manipulating the DOM of a HTML page. In crawling, you'll mostly use it to select the right elements and extract their text values - the data you're interested in. But <code>jQuery</code> runs in a browser and attaches directly to the browser's DOM. Where does <code>cheerio</code> get its HTML? This is where the <code>Crawler</code> part of <code>CheerioCrawler</code> comes in.</p>
<blockquote>
<p>TO BE CONTINUED ...</p>
</blockquote>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/docs/guides/motivation"><span class="arrow-prev">← </span><span>Motivation</span></a><a class="docs-next button" href="/docs/guides/gettingstartedquick"><span>Getting Started Quick</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#intro">Intro</a></li><li><a href="#setting-up-locally">Setting up locally</a><ul class="toc-headings"><li><a href="#adding-apify-sdk-to-an-existing-project">Adding Apify SDK to an existing project</a></li><li><a href="#creating-a-new-project">Creating a new project</a></li></ul></li><li><a href="#setting-up-on-the-apify-platform">Setting up on the Apify Platform</a><ul class="toc-headings"><li><a href="#creating-a-new-project-1">Creating a new project</a></li></ul></li><li><a href="#first-crawler">First crawler</a><ul class="toc-headings"><li><a href="#the-general-idea">The general idea</a></li><li><a href="#the-where-request-requestlist-and-requestqueue">The Where - <code>Request</code>, <code>RequestList</code> and <code>RequestQueue</code></a></li><li><a href="#the-what-handlepagefunction">The What - <code>handlePageFunction</code></a></li><li><a href="#putting-it-all-together">Putting it all together</a></li></ul></li><li><a href="#cheeriocrawler-aka-jquery-crawler">CheerioCrawler aka jQuery crawler</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/apify_logo.svg" alt="Apify SDK" width="66" height="58"/></a><div><h5>Docs</h5><a href="/docs/guides/motivation">Guide</a><a href="/docs/examples/basiccrawler">Examples</a><a href="/docs/api/apify">Reference</a></div><div><h5>Community</h5><a href="https://stackoverflow.com/questions/tagged/apify" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://twitter.com/apify" target="_blank" rel="noreferrer noopener">Twitter</a><a href="https://www.facebook.com/apifytech" target="_blank" rel="noreferrer noopener">Facebook</a></div><div><h5>More</h5><a href="https://www.apify.com" target="_blank">Apify Cloud</a><a href="https://docusaurus.io" target="_blank">Docusaurus</a><a href="https://github.com/apifytech/apify-js" target="_blank">GitHub</a></div></section><section class="copyright">Copyright © 2019 Apify Technologies s.r.o.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '64ce2544769e34add0e6402688c86e92',
                indexName: 'apify_sdk',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>